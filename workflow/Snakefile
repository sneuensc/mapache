"""
Author: Samuel Neuenschwander, Diana Ivette Cruz, Lucas Anchieri, Anna-Sapfo Malaspinas 
Affiliation: DBC, UNIL
Aim: Map ancient DNA libraries to a reference genome
Date: 28/10/2019
"""

##########################################################################################
## read the config file
configfile: "config/config.yaml"

include : "rules/common.smk"


## default values
SAMPLES               = get_param1("SAMPLES", "samples.txt")
email                 = get_param1("email", "")
delim                 = get_param1("delim", "\s+")
mapper                = get_param2("mapping", "mapper", "bwa_aln") 

## mapping options
run_adapter_removal   = str2bool(get_param2("adapterremoval", "run", True))
run_remove_duplicates = str2bool(get_param2("markduplicates", "run", True))
run_mapDamage_rescale = str2bool(get_param2("mapdamage", "run_rescale", False)) 
run_realign           = str2bool(get_param2("realign", "run", True)) 
run_compute_md        = str2bool(get_param2("compute_md", "run", True))  

## stats
run_damage            = get_param2("stats", "run_damage", 'False')
run_depth             = str2bool(get_param2("stats", "run_depth", 'False'))
run_bammds            = str2bool(get_param2("stats", "run_bammds", 'False'))

## retry failed jobs
memory_increment_ratio  = float(get_param1("memory_increment_ratio", 1)) 
runtime_increment_ratio = float(get_param1("runtime_increment_ratio", 0))

## software versions
module_samtools       = get_param2("ENVMODULES", "samtools", "")
module_bowtie2        = get_param2("ENVMODULES", "bowtie2", "")
module_bwa            = get_param2("ENVMODULES", "bwa", "")
module_picard         = get_param2("ENVMODULES", "picard", "")
module_gatk3          = get_param2("ENVMODULES", "gatk3", "")
module_fastqc         = get_param2("ENVMODULES", "fastqc", "")
module_r              = get_param2("ENVMODULES", "r", "")
module_adapterremoval = get_param2("ENVMODULES", "adapterremoval", "")
module_mapdamage      = get_param2("ENVMODULES", "mapdamage", "")
module_multiqc        = get_param2("ENVMODULES", "multiqc", "")
module_bedtools       = get_param2("ENVMODULES", "bedtools", "")

        
##########################################################################################
## some test to verify that the minimal requirements are met

## is at least a reference genome defined
GENOME = list(config['GENOME'])
if len(GENOME) == 0:
    print("ERROR: Reference genome is not specified (parameter GENOME)!")
    os._exit(0)

## test if for each reference a fasta file is defined
for i in GENOME:
    if 'fasta' not in list(config['GENOME'][i]):
        print("ERROR: Parameter GENOME required, but not set!")
        os._exit(0)

## if the bam files have to be rescaled mapDamage has to be run
if run_mapDamage_rescale and get_param2("stats", "run_damage", "False") != 'mapDamage':
    print("ERROR: To use 'mapdamage:run_rescale' the parameter 'stats:run_damage' has to be set to 'mapDamage'!")
    os._exit(0)


## if one wants to extract the duplicates, MarkDuplicate has to mark the duplicates in order to extract them
extract_duplicates = str2bool(get_param2("markduplicates", "keep_duplicates", "False"))
if  extract_duplicates and 'REMOVE_DUPLICATES=true' in get_param2("markduplicates", "params", ""):
    print("ERROR: To use 'markduplicates:extract_duplicates' the parameter 'markduplicates:params' has NOT to contain 'REMOVE_DUPLICATES=true'!")
    os._exit(0)

##########################################################################################
## read the sample file
# SAMPLES="samples.txt"
db = pd.read_csv(SAMPLES, sep=delim)


## check number of columns and column names
if len(db.columns) == 6:
    paired_end=0        ## single-end library
    if not set(['ID','Data', 'MAPQ', 'LB', 'PL', 'SM']).issubset(db.columns):
        print("ERROR: The column names in the sample file are wrong! Expected are for single-end reads: ID, Data, MAPQ, LB, PL, SM")
        os._exit(0)    
elif len(db.columns) == 7:
    adaptrem_params = config["adaptrem_params"] if "adaptrem_params" in list(config) else ''
    if '--collapse' in adaptrem_params:
        paired_end=1    ## paired-end libraries, which are collapsed with adapterremoval
    else:
        paired_end=2    ## paired-end libraries, which are mapped as paired-end

    if not set(['ID','Data1', 'Data2', 'MAPQ', 'LB', 'PL', 'SM']).issubset(db.columns):
        print("ERROR: The column names in the sample file are wrong! Expected are for paired-end reads: ID, Data1, Data2, MAPQ, LB, PL, SM")
        os._exit(0)    
else: 
    print(f"ERROR: The number of columns in the sample file is wrong ({len(db.columns)} columns)!")
    os._exit(0)


## check if all IDs per LB and SM are unique
all_fastq = db.groupby(['ID','LB','SM'])['ID'].agg(['count']).reset_index()
if max(all_fastq['count']) > 1:
    print("ERROR: The ID's have to be unique within a library and sample!")
    os._exit(0)


## dataframe to nested dict
samples = {}
cols = [e for e in list(db.columns) if e not in ('SM', 'LB', 'ID')]
for index, row in db.iterrows():
    ## if key not present add new dict
    if row['SM'] not in samples:
        samples[row['SM']] = {}
    if row['LB'] not in samples[row['SM']]:
        samples[row['SM']][row['LB']] = {}
    if row['ID'] not in samples[row['SM']][row['LB']]:
        samples[row['SM']][row['LB']][row['ID']] = {}
    
    ## add all remaining columns to this dict
    for col in cols:
        samples[row['SM']][row['LB']][row['ID']][col] = row[col]




## Building dictionnary for libraries
all_libraries = db.groupby(['LB','SM'])['ID'].agg(['count']).reset_index()



##########################################################################################
include : "rules/Snakefile_index.smk"
include : "rules/Snakefile_stats.smk"
include : "rules/Snakefile_fastq.smk"
include : "rules/Snakefile_library.smk"
include : "rules/Snakefile_sample.smk"
##########################################################################################
##########################################################################################
localrules: all, dag, mapping, stats ## executed locally on a cluster


input_stats = ["results/04_stats/03_final_tables/SM.csv",
        "results/04_stats/03_final_tables/LB.csv",
        "results/04_stats/03_final_tables/FASTQ.csv"]


## rules all
rule all:
    """
    Computes all
    """
    input:
       # "logs/check_software_modules.done",
        ## final bam files
        expand("results/03_sample/03_final_sample/01_bam/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME),
        expand("results/03_sample/03_final_sample/01_bam_low_qual/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME),
        expand("results/03_sample/03_final_sample/01_bam_duplicate/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME) if extract_duplicates else [],
        ## summary statistics
        #expand("results/03_sample/04_stats/01_summary/sample_stats.{id_genome}.csv", id_genome=GENOME),
        #expand("results/03_sample/04_stats/01_summary/1_nb_reads.{id_genome}.png", id_genome=GENOME),
        #expand("results/03_sample/04_stats/01_summary/2_mapped.{id_genome}.png", id_genome=GENOME),
        #expand("results/03_sample/04_stats/01_summary/3_endogenous.{id_genome}.png", id_genome=GENOME),
        #expand("results/03_sample/04_stats/01_summary/4_duplication.{id_genome}.png", id_genome=GENOME),
        ## extended statistics at library level
        #expand("results/02_library/03_final_library/01_bam/{id_sample}/{id_library}.{id_genome}_depth.txt", id_sample=list(samples), id_genome=GENOME) if str2bool(get_param3("stats", "library", "depth", "False")) else [],
        ## extended statistics at sample level
        #expand("results/03_sample/04_stats/01_summary/5_AvgReadDepth.{id_genome}.svg", id_genome=GENOME) if str2bool(get_param3("stats", "sample", "depth", "False")) else [],
        #expand("results/03_sample/04_stats/01_summary/6_AvgReadDepth_MT.{id_genome}.svg", id_genome=GENOME) if str2bool(get_param3("stats", "sample", "depth", "False")) else [],
        #expand("results/03_sample/04_stats/01_summary/7_Sex.{id_genome}.svg", id_genome=GENOME) if str2bool(get_param3("stats", "sample", "depth", "False")) else [],
        input_stats

        #expand("results/03_sample/04_stats/01_summary/depth_stats_{id_genome}.csv", id_genome=GENOME)
       # expand("results/03_sample/03_final_sample/01_bam/{id_sample}.{id_genome}_depth.txt", id_sample=list(samples), id_genome=GENOME) if str2bool(get_param3("stats", "sample", "depth", "False")) else []
       # expand("results/03_sample/04_stats/02_depth/{id_sample}.{id_genome}_depth.txt", id_sample=list(samples), id_genome=GENOME)  #if bool(config.get("stats", {}).get("sample", {}).get("depth", "False"))


## rules dag (just pipeline)
rule dag:
    """
    Computes just the mapping (used to get a nice DAG)
    """
    input:
        expand("results/03_sample/03_final_sample/01_bam/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME),


rule mapping:
    """
    Computes just what is needed to get the final mapping (without any stats)
    """
    input:
       # "logs/check_software_modules.done",
        expand("results/03_sample/03_final_sample/01_bam/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME),
        expand("results/03_sample/03_final_sample/01_bam_low_qual/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME),
        expand("results/03_sample/03_final_sample/01_bam_duplicate/{id_sample}.{id_genome}.bam", id_sample=list(samples), id_genome=GENOME) if extract_duplicates else [],
        expand("results/03_sample/04_stats/01_summary/sample_stats.{id_genome}.csv", id_genome=GENOME)

rule stats:
    """
    Computes all statistics
    """
    input:
        expand("results/03_sample/04_stats/01_summary/sample_stats.{id_genome}.csv", id_genome=GENOME),
        #expand("results/04_stats/sample_depth.{id_genome}.csv", id_genome=GENOME) if run_depth else [],
        #get_damage(run_damage),
        expand("results/03_sample/04_stats/01_summary/1_nb_reads.{id_genome}.png", id_genome=GENOME),
        expand("results/03_sample/04_stats/01_summary/2_mapped.{id_genome}.png", id_genome=GENOME),
        expand("results/03_sample/04_stats/01_summary/3_endogenous.{id_genome}.png", id_genome=GENOME),
        expand("results/03_sample/04_stats/01_summary/4_duplication.{id_genome}.png", id_genome=GENOME)

    
onsuccess:
    print("Wow, \'snakemake_aDNA_mapping\' finished successfully!")
    if email != "":
        print(f"sending email to {email}")
        shell('mail -s "Snakemake workflow \'snakemake_aDNA_mapping\' finished successfully" {email} < {log}')

onerror:
    print("An error occurred, stored to 'snakemake.run.log'")
    shell("cat {log} > snakemake.run.log")
    if email != "":
        print(f"sending email to {email}")
        shell('mail -s "Snakemake workflow \'snakemake_aDNA_mapping\' finished with error(s)" {email} < {log}')
        
##########################################################################################


# rule check_software_modules:
#     """
#     Checks if software modules are available
#     """
#     output: 
#         touch("logs/check_software_modules.done")
#     params: 
#         modules=RequiredModules()
#     message: "--- Loading required modules"
#     threads: 1
#     shell: "{params.modules}"




##########################################################################################
##########################################################################################
